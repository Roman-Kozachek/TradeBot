{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(If something doesn't work - be sure to run Part 5, it has updated versions of each class, Parts 2 through 4 :)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will create an environment to train our model to trade currencies at the *FOREX* market.  \n",
    "But let's lay some ground rules for our environment first.  \n",
    "  \n",
    "1. The environment must behave just like real *FOREX* market would. This means that we must consider trading costs, time lag, commisions and changes in positions' prices over time;  \n",
    "  \n",
    "  \n",
    "2. It would be nice if our `Environment` class would work in the same way as `gym` environment by **OpenAI** team does, as it's pretty easy to work with and  it also provides some reference;  \n",
    "  \n",
    "  \n",
    "3. `Environment` class must work as fast as we can make it to, because model training will take enough time as it is.    \n",
    "   \n",
    "  \n",
    "While we're on the topic of our future DQNN model let's define some parts of it as well. The model will be trained using  historical information of market price changes, as well as current information about agent's state in the environment. For that reason we'll need to implement some method to return historical data and agent's state at each timestep as current `observation` of the environment. We will define a *single timestep* length equal to *one minute* of real time.\n",
    "  \n",
    "That said, we can now define our `Environment` class more thoroughly. Let's break down some of the basic methods our class will have.   \n",
    "  \n",
    "1. **`step(action)`**  \n",
    "Method takes an `action` as an argument and executes one of several actions: `Buy` definite amount of trading currency; `Sell` definite amount of trading currency; `Close` open positions; `Wait`, do nothing and wait; \n",
    "  \n",
    "\n",
    "2. **`reset()`**   \n",
    "Method resets all the local variables and returns an `observation`;  \n",
    "  \n",
    "\n",
    "3. **`_update_state()`**   \n",
    "Method iterates through our data and returns new `observation`, `reward`, `info` and `done` flag to our agent.  \n",
    "  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Let's get to coding!*  \n",
    "\n",
    "But first, as always, we need to load some necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import random\n",
    "from utils import *\n",
    "seed = 17\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our `Environment` class and set some of the important properties and methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    \n",
    "    def __init__(self, paths, timesteps, starting_funds=100, max_length=14, start_year=2017, end_year=2020,\\\n",
    "                 from_start=False, end_coef=0):\n",
    "        \"\"\"\n",
    "        In this method we will add some properties to our class as well as set some parameters.\n",
    "        \n",
    "        :param starting_funds: amount of starting funds \n",
    "        :param max_length: maximum length of a training episode \n",
    "        :param paths: a tuple of paths to historical data datasets\n",
    "        :param timesteps: a tuple of timesteps to return at each step\n",
    "        \"\"\"\n",
    "        self._starting_funds = starting_funds\n",
    "        self._max_length = max_length \n",
    "        self._from_start = from_start\n",
    "        self._end_coef = end_coef\n",
    "        path_to_1h, path_to_15min, path_to_5min, path_to_1min = paths \n",
    "        self._h1_timesteps, self._m15_timesteps, self._m5_timesteps, self._m1_timesteps = timesteps \n",
    "\n",
    "        self.h1_data = self._get_dataset(path_to_1h)\n",
    "        self.m15_data = self._get_dataset(path_to_15min)\n",
    "        self.m5_data = self._get_dataset(path_to_5min)\n",
    "        self.m1_data = self._get_dataset(path_to_1min)\n",
    "        \n",
    "        self.m15_data = self.m15_data.loc[self.m15_data.Date.dt.date < self.h1_data.Date.iloc[-1]]\n",
    "        self.m5_data = self.m5_data.loc[self.m5_data.Date.dt.date < self.h1_data.Date.iloc[-1]]\n",
    "        self.m1_data = self.m1_data.loc[self.m1_data.Date.dt.date < self.h1_data.Date.iloc[-1]]\n",
    "        \n",
    "        self._max_positions = 1  # number of positions that can be opened at the same time         \n",
    "        self._leverage = 500  # broker's leverage, a tool to provide small time traders more resources to trade with\n",
    "        self._commision = 45/(10**6)  # broker's commission per trade\n",
    "        self._amount_space = np.arange(1, 201)*1000  # range of tradeable currency amounts \n",
    "        \n",
    "        # This is our action space. First part indicates general action, second, if present, direction \n",
    "        # of trade and third is trading amount in percents\n",
    "        self.action_space = [\"open.1.2\", \"open.1.5\", \"open.1.10\", \"open.0.2\", \"open.0.5\", \"open.0.10\", \"close\", \"hold\"] \n",
    "        \n",
    "        self._dict_keys = {\"H\":\"Hour_LSTM\", \"M15\":\"M15_LSTM\", \"M5\":\"M5_LSTM\", \"M1\":\"M1_LSTM\", \"SI\":\"State_input\"}\n",
    "        self._start_time = pd.to_datetime(\"06:00\", format='%H:%M').time() # Start time of each episode\n",
    "        self._end_time = pd.to_datetime(\"20:00\", format='%H:%M').time() # End time of each episode\n",
    "        \n",
    "        # Create a list of starting indexes in selected time period\n",
    "        self._monday_indexes = self.m1_data.loc[(self.m1_data.Date.dt.time == self._start_time) &\\\n",
    "                                               (self.m1_data.Date.dt.weekday == 0) &\\\n",
    "                                              (self.m1_data.Date.dt.year.between(start_year,end_year)\\\n",
    "                                              )].index[int(self._h1_timesteps/24):]\n",
    "        \n",
    "        self._start_indexes = self.m1_data.loc[(self.m1_data.Date.dt.time == self._start_time) &\\\n",
    "                                               (self.m1_data.Date.dt.weekday.between(0,5)) &\\\n",
    "                                              (self.m1_data.Date.dt.year.between(start_year,end_year)\\\n",
    "                                              )].index[int(self._h1_timesteps/24):]\n",
    "        \n",
    "\n",
    "    \n",
    "    def _get_dataset(self, path):\n",
    "        \"\"\"This method loads dataset from provided path\"\"\"\n",
    "        \n",
    "        data = pd.read_csv(path).reset_index(drop=True)\n",
    "        data.Date = pd.to_datetime(data.Date, format='%Y-%m-%d %H:%M:%S')      \n",
    "        return data\n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def _update_state(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll define **`reset()`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset(self):\n",
    "    \"\"\"In this method we will perform actions to reset environment state\"\"\"\n",
    "    # First we'll get a new starting day in our dataset\n",
    "    if self._from_start:\n",
    "        self._first_day_index = np.where(self._start_indexes == self._monday_indexes[0])[0][0]\n",
    "    else:\n",
    "        \n",
    "        self._first_day_index = np.where(self._start_indexes ==\\\n",
    "                                         random.choice(self._monday_indexes[1:-2]))[0][0]\n",
    "        \n",
    "    self._day_index = 0\n",
    "    self._initial_index = self._start_indexes[self._first_day_index]\n",
    "    self._current_index = self._initial_index\n",
    "    self._current_state = self.m1_data.iloc[self._current_index]\n",
    "    \n",
    "    # Next we'll reset funds, balance and open_positions variables\n",
    "    self._funds = self._starting_funds\n",
    "    self._balance = self._funds \n",
    "    self._open_positions = {}\n",
    "    \n",
    "    # Here we'll initialize time queue with historical market data\n",
    "    self._init_time_deque()\n",
    "\n",
    "    # Finally we'll reset variables which we send to the agent and return first state\n",
    "    self._done = False\n",
    "    self._reward = 0\n",
    "    self._last_observation = self._get_observation()\n",
    "    self._info = {\"Balance\": None, \"Funds\": None}\n",
    "\n",
    "    return self._last_observation\n",
    "\n",
    "Environment.reset = reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to write two supporting methods in order for **`reset()`** to work: **`_init_time_deque()`** and **`_get_observation()`**.  \n",
    "  \n",
    "First one will initiate historical market data queue.\n",
    "Basic logic is this: earlier in **`__init__()`** method we got information about `current_state`, so let's just take last `n_timesteps` records previous to current state date and time from each dataset.  \n",
    "\n",
    "We must be careful though, because each timestep in the dataset contains information about Closing, Highest and Lowest prices during the period and we can't have our model looking in the future!  \n",
    "\n",
    "For that reason we'll have to take last `n_timesteps` beginning from the second last record where `date_time < current_state.date_time`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def _init_time_deque(self):\n",
    "    \"\"\"\n",
    "    In this method we'll initialize time queue which we'll use to save time when updating environment state\n",
    "    \"\"\"\n",
    "    h1 = self.h1_data.loc[self.h1_data.Date < self._current_state.Date][-self._h1_timesteps-1:-1] # get last values\n",
    "    self._h1_queue = deque(h1.iloc[:, 1:].to_numpy(), maxlen=self._h1_timesteps) # initiate queue and repeat for every dataset\n",
    "\n",
    "    m15 = self.m15_data.loc[self.m15_data.Date < self._current_state.Date][-self._m15_timesteps-1:-1]\n",
    "    self._m15_queue = deque(m15.iloc[:, 1:].to_numpy(), maxlen=self._m15_timesteps)\n",
    "\n",
    "    m5 = self.m5_data.loc[self.m5_data.Date < self._current_state.Date][-self._m5_timesteps-1:-1]\n",
    "    self._m5_queue = deque(m5.iloc[:, 1:].to_numpy(), maxlen=self._m5_timesteps)\n",
    "\n",
    "    m1 = self.m1_data.loc[self.m1_data.Date < self._current_state.Date][-self._m1_timesteps-1:-1]\n",
    "    self._m1_queue = deque(m1.iloc[:, 1:].to_numpy(), maxlen=self._m1_timesteps) \n",
    "    \n",
    "    \n",
    "Environment._init_time_deque = _init_time_deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second method will update queues and return observation based on current state of the environment. We'll leave **`_get_current_agent_state()`** as blank for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_observation(self):\n",
    "    \n",
    "    date_column_index = 0\n",
    "    \n",
    "    if self._current_state.Date.minute == 0:\n",
    "        row = self.h1_data.iloc[self.h1_data.loc[self.h1_data.Date == self._current_state.Date].index - 1].to_numpy()[0][1:] \n",
    "        self._h1_queue.append(row)\n",
    "\n",
    "    if self._current_state.Date.minute % 15 == 0:\n",
    "        row = self.m15_data.iloc[self.m15_data.loc[self.m15_data.Date == self._current_state.Date].index - 1].to_numpy()[0][1:] \n",
    "        self._m15_queue.append(row)\n",
    "\n",
    "    if self._current_state.Date.minute % 5 == 0:\n",
    "        row = self.m5_data.iloc[self.m5_data.loc[self.m5_data.Date == self._current_state.Date].index - 1].to_numpy()[0][1:] \n",
    "        self._m5_queue.append(row)\n",
    "\n",
    "    row = self.m1_data.iloc[self.m1_data.loc[self.m1_data.Date == self._current_state.Date].index - 1].to_numpy()[0][1:]   \n",
    "    self._m1_queue.append(row)\n",
    "\n",
    "    state = self._get_current_agent_state()\n",
    "\n",
    "    return {self._dict_keys[\"H\"]: np.expand_dims(np.array(self._h1_queue), axis=0).astype(np.float32),\\\n",
    "            self._dict_keys[\"M15\"]: np.expand_dims(np.array(self._m15_queue), axis=0).astype(np.float32),\\\n",
    "            self._dict_keys[\"M5\"]: np.expand_dims(np.array(self._m5_queue), axis=0).astype(np.float32),\\\n",
    "            self._dict_keys[\"M1\"]: np.expand_dims(np.array(self._m1_queue), axis=0).astype(np.float32),\\\n",
    "            self._dict_keys[\"SI\"]: np.expand_dims(np.array(state), axis=0).astype(np.float32)}\n",
    "\n",
    "def _get_current_agent_state(self):\n",
    "    pass\n",
    "\n",
    "Environment._get_observation = _get_observation\n",
    "Environment._get_current_agent_state = _get_current_agent_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we're ready to define **`step()`** method for our environment. But before we do, let's define it's logic as well as some transaction formulas.  \n",
    "  \n",
    "When an `agent` tells `environment` to `Open` a position one of two things may happen. Either a new position will be opened or nothing will happen since `agent` already has maximum amount of open positions.  \n",
    "  \n",
    "In case new position can be opened following steps will take place:  \n",
    "1. First we define `direction` of a newly opened position and choose appropriate `exchange_rate` (ask or bid) based on `current state`;  \n",
    "2. Next we select the closest amount of currency there is to operate to the selected percentage of current balance;  \n",
    "3. We calculate cost of leveraged trade `usd_cost`, amount of leveraged base currency `usd_amount`, amount of leveraged target currency `eur_amount` and `transaction_cost`;  \n",
    "4. Finally we can update `funds` property of the environment and add new `Position` object to `open_positions` dictionary.  \n",
    "  \n",
    "When an `agent` tells `environment` to `Close` open positions the environment will execute the following steps:  \n",
    "1. Calculate current amount of base currency that the position is worth and subtract from it the amount of base currency position was opened for, getting overall profit of the trade;\n",
    "2. Add this profit to the `funds` field of the environment, minus the transaction cost;\n",
    "3. Finally set the `open` flag of the position to `False`.  \n",
    "\n",
    "When an `agent` tells `environment` to `Hold` nothing really happens, it's just a way for the agent to do nothing and take it's time.  \n",
    "  \n",
    "As I said before we need to create a new class `Position` which will hold all of the information about a trade in it's properties.  \n",
    "Let's start with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Position:\n",
    "    \n",
    "    def __init__(self, state, direction, exchange_rate, transaction_cost, cost_usd, usd_amount, eur_amount, leverage):\n",
    "        self.state = state  # State at which the position was created\n",
    "        self.direction = direction  # Direction, Ask(1) or Bid(0)\n",
    "        \n",
    "        self.open_date = state.Date\n",
    "        self.open_exchange_rate = exchange_rate\n",
    "        self.open = True\n",
    "        \n",
    "        self.close_date = None\n",
    "        self.close_exchange_rate = 0\n",
    "        \n",
    "        self.transaction_cost = transaction_cost\n",
    "        \n",
    "        self.cost_usd = cost_usd  # Cost of the trade\n",
    "        self.usd_amount = usd_amount  # Leveraged base currency amount\n",
    "        self.eur_amount = eur_amount  # Leveraged target currency amount\n",
    "        self._leverage = leverage\n",
    "        self.current_profit = 0\n",
    "        \n",
    "        \n",
    "    def _update_position(self, current_state):\n",
    "        exchange_rate = current_state.Bid if self.direction==1 else current_state.Ask\n",
    "        cur_usd_amount = self.eur_amount*exchange_rate\n",
    "        self.current_profit = (cur_usd_amount - self.usd_amount) if self.direction==1 else (self.usd_amount - cur_usd_amount)\n",
    "    \n",
    "    \n",
    "    def get_value(self):\n",
    "        \"\"\"\n",
    "        Returns current value of an open trade and calculates profit\n",
    "        \"\"\"\n",
    "        return round(self.cost_usd + self.current_profit - self.transaction_cost, 2)\n",
    "    \n",
    "    def get_profit(self):\n",
    "        \"\"\"\n",
    "        Returns current profit of an open trade\n",
    "        \"\"\"\n",
    "        return round(self.current_profit - self.transaction_cost*2, 2)\n",
    "    \n",
    "    def close(self, current_state):\n",
    "        \"\"\"\n",
    "        Closes an open position\n",
    "        \"\"\"\n",
    "        self.close_exchange_rate = current_state.Bid if self.direction==1 else current_state.Ask\n",
    "        self.close_date = current_state.Date\n",
    "        self.open = False\n",
    "          \n",
    "            \n",
    "    def get_info(self):\n",
    "        return {\"Date\": self.open_date, \"Type\": \"Ask\" if self.direction==1 else \"Bid\",\\\n",
    "                \"At\": self.open_exchange_rate, \"Open\": self.open, \"C_Date\": self.close_date,\\\n",
    "                \"C_At\": self.close_exchange_rate, \\\n",
    "                \"Profit\": self.current_profit-self.transaction_cost*2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can finally define **`step()`** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(self, action):\n",
    "    \n",
    "        action = self.action_space[action]\n",
    "        action = action.split(\".\")\n",
    "        closing_profit = None\n",
    "        \n",
    "        # Taking action\n",
    "        if action[0]==\"open\":\n",
    "            if sum(1 for pos in self._open_positions.values() if pos.open) != self._max_positions:\n",
    "                direction = int(action[1])\n",
    "                usd_cost = self._balance*(0.01*int(action[2]))\n",
    "                exchange_rate = self._current_state.Ask if direction==1 else self._current_state.Bid\n",
    "                cost_space = self._amount_space*exchange_rate/self._leverage\n",
    "                usd_cost = cost_space[(np.abs(cost_space - usd_cost)).argmin()]\n",
    "\n",
    "                usd_amount = round(usd_cost*self._leverage, 2)\n",
    "                eur_amount = self._amount_space[np.where(cost_space == usd_cost)][0]\n",
    "                transaction_cost = round(self._commision*usd_amount, 2)\n",
    "                self._funds = round(self._funds - usd_cost - transaction_cost, 2)\n",
    "                self._open_positions[len(self._open_positions)] = Position(self._current_state, direction, exchange_rate,\\\n",
    "                                                                           transaction_cost, usd_cost, usd_amount, \\\n",
    "                                                                           eur_amount, self._leverage)\n",
    "        \n",
    "        if action[0]==\"close\":\n",
    "            self._close_positions()\n",
    "        \n",
    "        if action[0]==\"hold\":\n",
    "            pass\n",
    "        \n",
    "        self._update_state()\n",
    "        \n",
    "        return self._last_observation, self._reward, self._done, self._info\n",
    "    \n",
    "def _close_positions(self):\n",
    "    for key, position in self._open_positions.items():\n",
    "        if position.open:\n",
    "            self._funds = round(self._funds + position.get_value() - position.transaction_cost, 2)\n",
    "            position.close(self._current_state)\n",
    "                \n",
    "def _update_state(self):\n",
    "    pass\n",
    "\n",
    "Environment._update_state = _update_state\n",
    "Environment.step = step\n",
    "Environment._close_positions = _close_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are finally ready to construct the most important method - **`_update_state()`**. This method is the 'engine' of this class. It'll make everything move and rattle. Let's define it.  \n",
    "In this method we will update current state of the environment as well as check it's `done` conditions. The episode is `done` if one of the following conditions is satisfied:  \n",
    "1. The environment has reached it's maximum duration;\n",
    "2. The `balance` or `funds` fields became less or equal to zero.  \n",
    "  \n",
    "Also if current day is over we should close every open position and transition to the next day, saving remaining `funds` and `balance`.  \n",
    "  \n",
    "In this method we will also calculate reward. For that we'll construct a method that finds total value of all open positions.  \n",
    "  \n",
    "And let's write a method to fetch current agent's state in the environment back to agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_state(self): \n",
    "    \"\"\"\n",
    "    Updates the state of the environment\n",
    "    \"\"\"\n",
    "    if self._current_state.Date.time() >= self._end_time:  \n",
    "        self._close_positions()\n",
    "        self._balance = self._funds\n",
    "        \n",
    "        self._day_index +=1\n",
    "        self._current_index = self._start_indexes[self._first_day_index + self._day_index]\n",
    "        self._current_state = self.m1_data.iloc[self._current_index]\n",
    "        self._init_time_deque()\n",
    "\n",
    "    else:\n",
    "        self._current_index += 1\n",
    "        self._current_state = self.m1_data.iloc[self._current_index]\n",
    "    \n",
    "    self._update_open_positions()\n",
    "    \n",
    "    self._balance = round(self._funds + self._get_open_positions_value(), 2)\n",
    "    \n",
    "    if self._balance <= self._starting_funds*self._end_coef or self._funds <= self._starting_funds*self._end_coef:\n",
    "        self._done = True\n",
    "    if self._day_index >= self._max_length:\n",
    "        self._done = True\n",
    "    \n",
    "    \n",
    "    self._reward = self._balance \n",
    "    self._last_observation = self._get_observation()\n",
    "    self._info[\"Balance\"]  = round(self._balance, 2)\n",
    "    self._info[\"Funds\"] =  round(self._funds, 2)\n",
    "    self._info[\"Open_positions\"] = sum(1 for pos in self._open_positions.values() if pos.open)\n",
    "\n",
    "\n",
    "def _update_open_positions(self):\n",
    "    for position in self._open_positions.values():\n",
    "        if position.open:\n",
    "            position._update_position(self._current_state)\n",
    "    \n",
    "def _get_open_positions_value(self):\n",
    "    \"\"\"\n",
    "    Calculates value of currently open positions\n",
    "    \"\"\"\n",
    "    value = 0\n",
    "    for position in self._open_positions.values():\n",
    "        if position.open:\n",
    "            value += position.get_value()   \n",
    "    return value\n",
    "\n",
    "def _get_open_positions_profit(self):\n",
    "    \"\"\"\n",
    "    Calculates value of currently open positions\n",
    "    \"\"\"\n",
    "    profit = 0\n",
    "    for position in self._open_positions.values():\n",
    "        if position.open:\n",
    "            profit += position.get_profit()   \n",
    "            \n",
    "    return profit\n",
    "\n",
    "def _get_current_agent_state(self):\n",
    "    \"\"\"\n",
    "    Returns information about agent's state in the environment\n",
    "    \"\"\"\n",
    "    num_open = sum(1 for pos in self._open_positions.values() if pos.open) # Number of open positions\n",
    "    total_profit = sum(pos.current_profit for pos in self._open_positions.values() if pos.open) # Profit of open positions\n",
    "    \n",
    "    return (num_open, total_profit/self._balance, self._funds/self._balance,\\\n",
    "           self._current_state.Ask, self._current_state.Bid, self._current_state.Spread)\n",
    "\n",
    "\n",
    "Environment._update_state = _update_state\n",
    "Environment._update_open_positions = _update_open_positions\n",
    "Environment._get_open_positions_profit = _get_open_positions_profit\n",
    "Environment._get_open_positions_value = _get_open_positions_value\n",
    "Environment._get_current_agent_state = _get_current_agent_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done! Now let's run some tests in order to see if everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_1h = data_path + \"exp-EURUSD-bars-1h-2016Jan-2020Jan.csv\"\n",
    "path_to_15min = data_path + \"exp-EURUSD-bars-m15-2016Jan-2020Jan.csv\"\n",
    "path_to_5min = data_path + \"exp-EURUSD-bars-m5-2016Jan-2020Jan.csv\"\n",
    "path_to_1min = data_path + \"exp-EURUSD-bars-1m-2016Jan-2020Jan.csv\"\n",
    "paths = (path_to_1h, path_to_15min, path_to_5min, path_to_1min)\n",
    "timesteps = (48, 64, 64, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment(paths, timesteps, 100, 21, 2016, 2019, True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['open.1.2',\n",
       " 'open.1.5',\n",
       " 'open.1.10',\n",
       " 'open.0.2',\n",
       " 'open.0.5',\n",
       " 'open.0.10',\n",
       " 'close',\n",
       " 'hold']"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, reward, done, info = env.step(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 100.000000\n",
      "Done: False\n",
      "Information: {'Balance': 100, 'Funds': 100, 'Open_positions': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Reward: %.6f\" % reward)\n",
    "print(\"Done: {}\".format(done))\n",
    "print(\"Information: %s\" % info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buying and holding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, reward, done, info = env.step(1)\n",
    "for _ in range(100):\n",
    "    _, reward, done, info = env.step(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 99.000000\n",
      "Done: False\n",
      "Information: {'Balance': 99.0, 'Funds': 95.54, 'Open_positions': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Reward: %.6f\" % reward)\n",
    "print(\"Done: {}\".format(done))\n",
    "print(\"Information: %s\" % info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, reward, done, info = env.step(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 98.900000\n",
      "Done: False\n",
      "Information: {'Balance': 98.9, 'Funds': 98.9, 'Open_positions': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Reward: %.6f\" % reward)\n",
    "print(\"Done: {}\".format(done))\n",
    "print(\"Information: %s\" % info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    _, reward, done, info = env.step(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 98.900000\n",
      "Done: False\n",
      "Information: {'Balance': 98.9, 'Funds': 98.9, 'Open_positions': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Reward: %.6f\" % reward)\n",
    "print(\"Done: {}\".format(done))\n",
    "print(\"Information: %s\" % info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other way around now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, reward, done, info = env.step(3)\n",
    "for _ in range(100):\n",
    "    _, reward, done, info = env.step(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 100.350000\n",
      "Done: False\n",
      "Information: {'Balance': 100.35, 'Funds': 97.77, 'Open_positions': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Reward: %.6f\" % reward)\n",
    "print(\"Done: {}\".format(done))\n",
    "print(\"Information: %s\" % info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, reward, done, info = env.step(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 100.300000\n",
      "Done: False\n",
      "Information: {'Balance': 100.3, 'Funds': 100.3, 'Open_positions': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Reward: %.6f\" % reward)\n",
    "print(\"Done: {}\".format(done))\n",
    "print(\"Information: %s\" % info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    _, reward, done, info = env.step(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 100.300000\n",
      "Done: False\n",
      "Information: {'Balance': 100.3, 'Funds': 100.3, 'Open_positions': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Reward: %.6f\" % reward)\n",
    "print(\"Done: {}\".format(done))\n",
    "print(\"Information: %s\" % info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splendid. I'll save this class to a file and we can move onto the next step - creating an agent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1562px",
    "right": "20px",
    "top": "103px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
